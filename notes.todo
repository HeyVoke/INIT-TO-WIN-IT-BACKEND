# Steps to Take

1. Collect Expected Data:
    - Gather CSVs from the wearable.
    - Export JSON files from your questionnaire.
    - Collect text files or logs from diary entries.
    - Will Cross-analyze questionnaire, sleep, and diary data.

5. Hackathon Mode (Quick Setup):
    - Store raw data in Blob Storage.
    - Use Azure Functions or Logic Apps to transform data.
    - Save processed data in Cosmos DB or SQLite on Azure.
        - structured storage for efficient querying and joining

2. Define App Features:
    - Show user dashboards or trends (e.g., â€œYour REM sleep improved when you felt financially secureâ€).

Suggested Repo Structure
backend/
â”‚
â”œâ”€â”€ app/                            # Main FastAPI app
â”‚   â”œâ”€â”€ main.py                     # FastAPI entry point
â”‚   â”œâ”€â”€ api/                        # Route definitions
â”‚   â”‚   â”œâ”€â”€ insights.py             # Routes for AI suggestions
â”‚   â”œâ”€â”€ services/                   # Core logic
â”‚   â”‚   â”œâ”€â”€ blob_storage.py         # Upload/download wearable CSV files
â”‚   â”‚   â”œâ”€â”€ mongo_db.py             # Interact with MongoDB
â”‚   â”‚   â”œâ”€â”€ llm.py                  # Generate AI suggestions
â”‚   â””â”€â”€ models/                     # Pydantic schemas
â”‚       â”œâ”€â”€ insights.py
â”‚       â””â”€â”€ sleep.py
â”‚
â”œâ”€â”€ ingestion/                      # Scripts & automation for ingesting wearable CSV
â”‚   â”œâ”€â”€ upload_csv.py               # Upload CSV to mongoDB
â”‚   â””â”€â”€ samples/                    # Example wearable tech CSVs (for hackathon)
â”‚       â””â”€â”€ example_sleep_data.csv
â”‚
â”œâ”€â”€ azure_functions/               # Azure Functions (Blob trigger to clean CSV)
â”‚   â”œâ”€â”€ clean_sleep_data/          # Triggered when wearable CSV is uploaded
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ function.json
â”‚   â”‚   â””â”€â”€ processor.py           # Cleans & loads into MongoDB
â”‚   â””â”€â”€ shared/                    # Shared utilities
â”‚       â”œâ”€â”€ utils.py
â”‚       â””â”€â”€ config.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ host.json                      # For Azure Functions
â””â”€â”€ README.md


ğŸ” **Flow Overview**

- **Frontend sends raw data** â†’ `POST /api/ingest` â†’ FastAPI
- **FastAPI (`ingest.py`)** calls `blob_storage.py` â†’ uploads raw data to Blob
- **Azure Function (`clean_data_func`)** is triggered (e.g., by Blob upload event):
    - Downloads raw data
    - Cleans and transforms it
    - Saves clean data to MongoDB
- **Later requests from frontend**:
    - `/api/insights`: FastAPI loads clean data from MongoDB, prompts LLM
    - `/api/sleep-analysis`: FastAPI runs sleep stats on clean MongoDB data

---

ğŸ’¬ **Azure Functions: Placement & Role**

- **Separation**: Your Azure Functions are separate from FastAPI but can live in the same monorepo under the `azure_functions/` folder.
- **Trigger Type**: Blob trigger
- **Responsibilities**:
    - Receive raw data blob
    - Parse, clean, validate
    - Store structured data into MongoDB
- **Deployment**: If needed, you can deploy Azure Functions separately, independent of your FastAPI app on Azure App Service.

---

ğŸ’¡ **Tips**

1. Use `.env` or a config manager for shared secrets across FastAPI and Azure Functions.
2. If your AI model is hosted (e.g., Azure OpenAI or OpenAI API), wrap API calls in `services/llm.py`.
3. For local development, use **Azurite** for Blob storage mocking.
4. MongoDB access should be wrapped in reusable classes/functions â€” avoid raw queries in routes.


Tasks:
â˜ Agree on the repo structure
â˜ Create a new repo
â˜ Data Ingestion + Storage:
    â˜ Create a script to upload CSVs to Azure (Wearable data)
    â˜ Create a script to upload survey JSONs to Azure (Questionnaire data)
    â˜ Create a script to upload text files to Azure (Diary data)
â˜ Data Cleaning + Storage:
    â˜ Create a script to clean and transform wearable CSVs (Azure Functions)
â˜ Create a script to generate insights using LLM - promt engineering etc.
â˜ Create a script to analyze sleep data (Will this be fed to the LLM?) - any key metrics like percantage of time in REM, etc.



